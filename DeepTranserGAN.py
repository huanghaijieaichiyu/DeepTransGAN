'''
code by é»„å°æµ·  2025/2/19

è¿™æ˜¯ä¸€ä¸ªåŸºäºPyTorchçš„æ·±åº¦å­¦ä¹ é¡¹ç›®ï¼Œç”¨äºä½å…‰ç…§å›¾åƒå¢å¼ºã€‚
æ•°æ®é›†ç»“æ„ï¼š
- datasets
    - kitti_LOL
        - eval15
            - high
            - low
        - our485
            - high
            - low
- DeepTranserGAN



'''
import os
import time
import cv2
import imageio
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import autocast
from torch.optim.lr_scheduler import StepLR
from torch.utils import tensorboard
from torch.utils.data import DataLoader
from torcheval.metrics.functional import peak_signal_noise_ratio
from torchvision import transforms
from tqdm import tqdm
import torch.amp as amp  # æ›´æ–°å¯¼å…¥ä»¥ä½¿ç”¨æ–°çš„autocast API

from datasets.data_set import LowLightDataset
from models.base_mode import Generator, Discriminator, LightSWTformer
from utils.loss import BCEBlurWithLogitsLoss
from utils.misic import set_random_seed, get_opt, get_loss, ssim, model_structure, save_path


# æ·»åŠ  SpectralNorm å®ç°ï¼Œç”¨äºç¨³å®šåˆ¤åˆ«å™¨è®­ç»ƒ
def spectral_norm(module, name='weight', power_iterations=1):
    """
    å¯¹æ¨¡å—åº”ç”¨è°±å½’ä¸€åŒ–
    """
    if isinstance(module, (nn.Conv2d, nn.Linear)):
        original_method = module.forward

        u = torch.randn(module.weight.size(0), 1, requires_grad=False)
        u = u.to(module.weight.device)

        def _l2normalize(v):
            return v / (torch.norm(v) + 1e-12)

        def spectral_norm_forward(*args, **kwargs):
            weight = module.weight
            weight_mat = weight.view(weight.size(0), -1)

            for _ in range(power_iterations):
                v = _l2normalize(torch.matmul(weight_mat.t(), u))
                u.data = _l2normalize(torch.matmul(weight_mat, v))

            sigma = torch.dot(u.view(-1), torch.matmul(weight_mat, v).view(-1))
            weight = weight / sigma

            return original_method(*args, **kwargs)

        module.forward = spectral_norm_forward

    return module

# æ·»åŠ  SpectralNormConv2d ç±»ï¼Œç”¨äºæ›¿æ¢åˆ¤åˆ«å™¨ä¸­çš„å·ç§¯å±‚


class SpectralNormConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels,
                              kernel_size, stride, padding, bias=bias)
        self.conv = spectral_norm(self.conv)

    def forward(self, x):
        return self.conv(x)


class BaseTrainer:
    def __init__(self, args, generator, discriminator=None, critic=None):
        self.n_pretain = 2  # å‡å°‘åˆ¤åˆ«å™¨é¢„è®­ç»ƒæ¬¡æ•°ï¼Œé¿å…è¿‡åº¦è®­ç»ƒ
        self.args = args
        self.generator = generator
        self.discriminator = discriminator
        self.critic = critic
        self.device = torch.device('cpu')
        if args.device == 'cuda':
            self.device = torch.device(
                'cuda:0' if torch.cuda.is_available() else 'cpu')
        self.generator = self.generator.to(self.device)

        # åˆå§‹åŒ–ç”Ÿæˆå™¨æƒé‡
        self._initialize_weights(self.generator)

        if self.discriminator is not None:
            self.discriminator = self.discriminator.to(self.device)
            # åˆå§‹åŒ–åˆ¤åˆ«å™¨æƒé‡
            self._initialize_weights(self.discriminator)
            # åº”ç”¨è°±å½’ä¸€åŒ–åˆ°åˆ¤åˆ«å™¨
            self._apply_spectral_norm(self.discriminator)
        if self.critic is not None:
            self.critic = self.critic.to(self.device)
            # åˆå§‹åŒ–è¯„è®ºå™¨æƒé‡
            self._initialize_weights(self.critic)
            # åº”ç”¨è°±å½’ä¸€åŒ–åˆ°è¯„è®ºå™¨
            self._apply_spectral_norm(self.critic)

        # å¢å¼ºæ•°æ®å¢å¼º
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(p=0.5),  # éšæœºæ°´å¹³ç¿»è½¬
            transforms.RandomRotation(10),  # éšæœºæ—‹è½¬Â±10åº¦
            transforms.ColorJitter(brightness=0.1, contrast=0.1),  # äº®åº¦å’Œå¯¹æ¯”åº¦å˜åŒ–
            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # å°å¹…å¹³ç§»
            transforms.ToTensor(),
            # transforms.Normalize(
            #     (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # æ ‡å‡†åŒ–åˆ° [-1, 1]
        ])

        self.train_data = LowLightDataset(
            image_dir=args.data, transform=self.transform, phase="train")
        self.train_loader = DataLoader(self.train_data, batch_size=args.batch_size, num_workers=args.num_workers,
                                       shuffle=True, drop_last=True, pin_memory=True)  # å¯ç”¨pin_memoryåŠ é€Ÿæ•°æ®ä¼ è¾“

        # æµ‹è¯•æ•°æ®ä¸éœ€è¦å¢å¼ºï¼Œä½†éœ€è¦æ ‡å‡†åŒ–
        self.test_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize(
            #    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # æ ‡å‡†åŒ–åˆ° [-1, 1]
        ])

        self.test_data = LowLightDataset(
            image_dir=args.data, transform=self.test_transform, phase="test")
        self.test_loader = DataLoader(self.test_data, batch_size=args.batch_size, num_workers=args.num_workers,
                                      shuffle=False, drop_last=False, pin_memory=True)

        # ä¼˜åŒ–å™¨åˆå§‹åŒ– - ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡
        self.g_optimizer, self.d_optimizer = self._get_optimizers(args)

        # æŸå¤±å‡½æ•°ç»„åˆ
        self.g_loss = get_loss(args.loss).to(
            self.device) if args.loss else nn.MSELoss().to(self.device)
        self.stable_loss = nn.SmoothL1Loss().to(self.device)

        # è·¯å¾„è®¾ç½®
        self.path = save_path(
            args.save_path) if args.resume == '' else args.resume
        self.log = tensorboard.writer.SummaryWriter(log_dir=self.path, filename_suffix=str(args.epochs),
                                                    flush_secs=180)

        # æ¨¡å‹ä¿å­˜ç­–ç•¥
        self.best_psnr = 0.0
        self.best_ssim = 0.0
        self.patience = args.patience if hasattr(args, 'patience') else 10
        self.patience_counter = 0
        self.eval_interval = 5  # æ¯5ä¸ªepochè¯„ä¼°ä¸€æ¬¡

        # å­¦ä¹ ç‡è°ƒåº¦ - ä½¿ç”¨ä½™å¼¦é€€ç«
        self.scheduler_g = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.g_optimizer, T_0=10, T_mult=2, eta_min=args.lr * 0.001)
        if self.d_optimizer is not None:
            self.scheduler_d = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
                self.d_optimizer, T_0=10, T_mult=2, eta_min=args.lr * 0.001)
        else:
            self.scheduler_d = None

        # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        self.grad_accum_steps = args.grad_accum_steps if hasattr(
            args, 'grad_accum_steps') else 1

        # æ ‡ç­¾å¹³æ»‘å‚æ•°
        self.label_smoothing = 0.1

        # æ¢¯åº¦æƒ©ç½šæƒé‡
        self.lambda_gp = 10

        # æ·»åŠ å™ªå£°åˆ°åˆ¤åˆ«å™¨è¾“å…¥
        self.noise_factor = 0.05

        # ä¸¤æ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ (TTUR)
        self.d_updates_per_g = 2  # æ¯è®­ç»ƒä¸€æ¬¡ç”Ÿæˆå™¨ï¼Œè®­ç»ƒåˆ¤åˆ«å™¨çš„æ¬¡æ•°

        # NaNæ£€æµ‹å’Œå¤„ç†
        self.nan_detected = False
        self.nan_count = 0
        self.max_nan_count = 5  # è¿ç»­NaNæ¬¡æ•°é˜ˆå€¼

        # æ„ŸçŸ¥æŸå¤±æƒé‡
        self.perceptual_weight = 0.5  # å¢åŠ æ„ŸçŸ¥æŸå¤±æƒé‡

        # ç¡®ä¿è·¯å¾„å­˜åœ¨
        if self.args.resume == '':
            os.makedirs(os.path.join(self.path, 'generator'), exist_ok=True)
            if self.discriminator is not None:
                os.makedirs(os.path.join(
                    self.path, 'discriminator'), exist_ok=True)
            if self.critic is not None:
                os.makedirs(os.path.join(self.path, 'critic'), exist_ok=True)

        self.train_log = self.path + '/log.txt'
        self.args_dict = args.__dict__
        self.epoch = 0
        self.Ssim = [0.]
        self.PSN = [0.]

        # è®°å½•è®­ç»ƒé…ç½®
        self._log_training_config()

        # å¯¼å…¥ rich åº“ç”¨äºç¾åŒ–æ˜¾ç¤º
        try:
            from rich.console import Console
            from rich.table import Table
            from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, TimeRemainingColumn
            self.rich_available = True
            self.console = Console()
        except ImportError:
            self.rich_available = False
            print("æç¤º: å®‰è£… rich åº“å¯ä»¥è·å¾—æ›´ç¾è§‚çš„è®­ç»ƒæ˜¾ç¤ºæ•ˆæœ (pip install rich)")

        # ç®€åŒ–æŸå¤±å‡½æ•°é…ç½®
        self.pixel_loss_weight = 10.0  # åƒç´ æŸå¤±æƒé‡

        # æ·»åŠ æ¢¯åº¦ç¼©æ”¾å› å­ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.gradient_scale = 0.1

        # æ·»åŠ å­¦ä¹ ç‡è°ƒæ•´å› å­
        self.lr_decay_factor = 0.5
        self.lr_decay_patience = 5
        self.lr_decay_counter = 0

        # æ·»åŠ æ¢¯åº¦è£å‰ªå€¼
        self.grad_clip_discriminator = 0.5
        self.grad_clip_generator = 1.0

    def _log_training_config(self):
        """è®°å½•è®­ç»ƒé…ç½®åˆ°æ—¥å¿—æ–‡ä»¶"""
        with open(self.train_log, "a") as f:
            f.write("=== Training Configuration ===\n")
            for key, value in self.args_dict.items():
                f.write(f"{key}: {value}\n")
            f.write("============================\n\n")

    def load_checkpoint(self):
        if self.args.resume != '':
            # åŠ è½½ç”Ÿæˆå™¨
            g_path_checkpoint = os.path.join(
                self.args.resume, 'generator/last.pt')
            if os.path.exists(g_path_checkpoint):
                g_checkpoint = torch.load(
                    g_path_checkpoint, map_location=self.device)
                self.generator.load_state_dict(g_checkpoint['net'])
                self.g_optimizer.load_state_dict(g_checkpoint['optimizer'])
                self.epoch = g_checkpoint['epoch']
                if 'best_psnr' in g_checkpoint:
                    self.best_psnr = g_checkpoint['best_psnr']
                if 'best_ssim' in g_checkpoint:
                    self.best_ssim = g_checkpoint['best_ssim']
                if 'scheduler' in g_checkpoint:
                    self.scheduler_g.load_state_dict(g_checkpoint['scheduler'])
            else:
                raise FileNotFoundError(
                    f"Generator checkpoint {g_path_checkpoint} not found.")

            # åŠ è½½åˆ¤åˆ«å™¨æˆ–è¯„è®ºå™¨
            d_path_checkpoint = os.path.join(
                self.args.resume, 'discriminator/last.pt') if self.discriminator else os.path.join(self.args.resume, 'critic/last.pt')
            if os.path.exists(d_path_checkpoint):
                d_checkpoint = torch.load(
                    d_path_checkpoint, map_location=self.device)
                if self.discriminator:
                    self.discriminator.load_state_dict(d_checkpoint['net'])
                elif self.critic:
                    self.critic.load_state_dict(d_checkpoint['net'])
                if self.d_optimizer is not None:
                    self.d_optimizer.load_state_dict(d_checkpoint['optimizer'])
                    if 'scheduler' in d_checkpoint and self.scheduler_d is not None:
                        self.scheduler_d.load_state_dict(
                            d_checkpoint['scheduler'])
            else:
                raise FileNotFoundError(
                    f"Discriminator/Critic checkpoint {d_path_checkpoint} not found.")

            print(f'Continuing training from epoch: {self.epoch + 1}')
            self.path = self.args.resume
            self.args.resume = ''

    def save_checkpoint(self, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œå¯é€‰æ‹©æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹"""
        save_path = os.path.join(
            self.path, 'generator', 'best.pt' if is_best else 'last.pt')

        # ä¿å­˜ç”Ÿæˆå™¨
        g_checkpoint = {
            'net': self.generator.state_dict(),
            'optimizer': self.g_optimizer.state_dict(),
            'epoch': self.epoch,
            'best_psnr': self.best_psnr,
            'best_ssim': self.best_ssim,
            'scheduler': self.scheduler_g.state_dict()
        }
        torch.save(g_checkpoint, save_path)

        # ä¿å­˜åˆ¤åˆ«å™¨æˆ–è¯„è®ºå™¨
        d_save_path = os.path.join(
            self.path,
            'discriminator' if self.discriminator else 'critic',
            'best.pt' if is_best else 'last.pt'
        )

        d_net_state = None
        if self.discriminator is not None:
            d_net_state = self.discriminator.state_dict()
        elif self.critic is not None:
            d_net_state = self.critic.state_dict()

        if d_net_state is not None and self.d_optimizer is not None:
            d_checkpoint = {
                'net': d_net_state,
                'optimizer': self.d_optimizer.state_dict(),
                'epoch': self.epoch,
            }
            if self.scheduler_d is not None:
                d_checkpoint['scheduler'] = self.scheduler_d.state_dict()

            torch.save(d_checkpoint, d_save_path)

    def log_message(self, message):
        print(message)
        with open(self.train_log, "a") as f:
            f.write(f"{message}\n")

    def write_log(self, epoch, gen_loss, dis_loss, d_x, d_g_z1, d_g_z2):
        train_log_txt_formatter = (
            '{time_str} \t [Epoch] \t {epoch:03d} \t [gLoss] \t {gloss_str} \t [dLoss] \t {dloss_str} \t {Dx_str} \t ['
            'Dgz0] \t {Dgz0_str} \t [Dgz1] \t {Dgz1_str}\n')
        to_write = train_log_txt_formatter.format(time_str=time.strftime("%Y_%m_%d_%H:%M:%S"), epoch=epoch + 1,
                                                  gloss_str=" ".join(
                                                      ["{:4f}".format(np.mean(gen_loss))]),
                                                  dloss_str=" ".join(
                                                      ["{:4f}".format(np.mean(dis_loss))]),
                                                  Dx_str=" ".join(
                                                      ["{:4f}".format(d_x)]),
                                                  Dgz0_str=" ".join(
                                                      ["{:4f}".format(d_g_z1)]),
                                                  Dgz1_str=" ".join(["{:4f}".format(d_g_z2)]))
        with open(self.train_log, "a") as f:
            f.write(to_write)

    def visualize_results(self, epoch, gen_loss, dis_loss, high_images, low_images, fake):
        self.log.add_scalar('generation loss', np.mean(gen_loss), epoch + 1)
        self.log.add_scalar('discrimination loss',
                            np.mean(dis_loss), epoch + 1)
        self.log.add_scalar('learning rate', self.g_optimizer.state_dict()[
                            'param_groups'][0]['lr'], epoch + 1)
        self.log.add_images('real', high_images, epoch + 1)
        self.log.add_images('input', low_images, epoch + 1)
        self.log.add_images('fake', fake, epoch + 1)

    def evaluate_model(self):
        with torch.no_grad():
            self.log_message(
                f"Evaluating the generator model at epoch {self.epoch + 1}")
            self.generator.eval()
            if self.discriminator:
                self.discriminator.eval()
            elif self.critic:
                self.critic.eval()

            Ssim = []
            PSN = []

            for i, (low_images, high_images) in enumerate(self.test_loader):
                low_images = low_images.to(self.device)
                high_images = high_images.to(self.device)

                # ç”Ÿæˆå¢å¼ºå›¾åƒ
                fake_eval = self.generator(low_images)

                # è®¡ç®—SSIMå’ŒPSNR
                ssim_value = ssim(fake_eval, high_images).item()
                psnr_value = peak_signal_noise_ratio(
                    fake_eval, high_images).item()

                Ssim.append(ssim_value)
                PSN.append(psnr_value)

            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_ssim = np.mean(Ssim)
            avg_psnr = np.mean(PSN)

            # è®°å½•åˆ°TensorBoard
            self.log.add_scalar('SSIM', avg_ssim, self.epoch + 1)
            self.log.add_scalar('PSNR', avg_psnr, self.epoch + 1)

            self.log_message(
                f"Model SSIM: {avg_ssim:.4f}  PSNR: {avg_psnr:.4f}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            is_best = False
            if avg_psnr > self.best_psnr:
                self.log_message(
                    f"New best PSNR: {avg_psnr:.4f} (previous: {self.best_psnr:.4f})")
                self.best_psnr = avg_psnr
                is_best = True
                self.patience_counter = 0
            elif avg_ssim > self.best_ssim:
                self.log_message(
                    f"New best SSIM: {avg_ssim:.4f} (previous: {self.best_ssim:.4f})")
                self.best_ssim = avg_ssim
                is_best = True
                self.patience_counter = 0
            else:
                self.patience_counter += 1
                self.log_message(
                    f"No improvement. Patience: {self.patience_counter}/{self.patience}")

            # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æ£€æŸ¥ç‚¹
            if is_best:
                self.save_checkpoint(is_best=True)

            # æ£€æŸ¥æ—©åœ
            if self.patience_counter >= self.patience:
                self.log_message("Early stopping triggered.")
                return True  # åœæ­¢è®­ç»ƒ

            return False

    def create_rich_progress(self):
        """åˆ›å»ºç¾åŒ–çš„è¿›åº¦æ¡"""
        if not self.rich_available:
            return None

        from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, TimeRemainingColumn

        return Progress(
            TextColumn("[bold blue]{task.description}"),
            BarColumn(bar_width=40),
            TaskProgressColumn(),
            TextColumn("â€¢"),
            TimeElapsedColumn(),
            TextColumn("â€¢"),
            TimeRemainingColumn(),
            expand=True
        )

    def print_epoch_summary(self, epoch, gen_loss, dis_loss, metrics=None):
        """æ‰“å°æ¯ä¸ªepochç»“æŸæ—¶çš„è®­ç»ƒæ‘˜è¦"""
        metrics = metrics or {}

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_gen_loss = sum(gen_loss) / len(gen_loss) if gen_loss else 0
        avg_dis_loss = sum(dis_loss) / len(dis_loss) if dis_loss else 0

        if self.rich_available:
            from rich.table import Table

            # åˆ›å»ºè¡¨æ ¼
            table = Table(
                title=f"ğŸ“Š è®­ç»ƒæ‘˜è¦ - Epoch {epoch + 1}/{self.args.epochs}", expand=True)

            # æ·»åŠ åˆ—
            table.add_column("ç±»åˆ«", style="cyan")
            table.add_column("æŒ‡æ ‡", style="magenta")
            table.add_column("æ•°å€¼", style="green")

            # æ·»åŠ æŸå¤±æ•°æ®
            table.add_row("æŸå¤±", "ç”Ÿæˆå™¨å¹³å‡æŸå¤±", f"{avg_gen_loss:.6f}")
            table.add_row("æŸå¤±", "åˆ¤åˆ«å™¨å¹³å‡æŸå¤±", f"{avg_dis_loss:.6f}")

            # æ·»åŠ å­¦ä¹ ç‡æ•°æ®
            if hasattr(self, 'g_optimizer') and self.g_optimizer is not None:
                g_lr = self.g_optimizer.param_groups[0]['lr']
                table.add_row("å­¦ä¹ ç‡", "ç”Ÿæˆå™¨", f"{g_lr:.6f}")
            if hasattr(self, 'd_optimizer') and self.d_optimizer is not None:
                d_lr = self.d_optimizer.param_groups[0]['lr']
                table.add_row("å­¦ä¹ ç‡", "åˆ¤åˆ«å™¨/è¯„è®ºå™¨", f"{d_lr:.6f}")

            # æ·»åŠ å…¶ä»–æŒ‡æ ‡
            for key, value in metrics.items():
                table.add_row("æŒ‡æ ‡", key, f"{value}" if isinstance(
                    value, str) else f"{value:.4f}")

            # æ·»åŠ å†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                table.add_row(
                    "GPUå†…å­˜", "å·²åˆ†é…", f"{torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                table.add_row(
                    "GPUå†…å­˜", "ç¼“å­˜", f"{torch.cuda.memory_reserved() / 1024**2:.2f} MB")
                table.add_row(
                    "GPUå†…å­˜", "æœ€å¤§åˆ†é…", f"{torch.cuda.max_memory_allocated() / 1024**2:.2f} MB")

            # æ‰“å°è¡¨æ ¼
            self.console.print()
            self.console.print(table)
            self.console.print()
        else:
            # åˆ›å»ºåˆ†éš”çº¿
            separator = "=" * 80

            # æ‰“å°æ‘˜è¦
            print(f"\n{separator}")
            print(f"ğŸ“Š è®­ç»ƒæ‘˜è¦ - Epoch {epoch + 1}/{self.args.epochs}")
            print(f"{separator}")

            # æŸå¤±ä¿¡æ¯
            print(f"ğŸ“‰ æŸå¤±ç»Ÿè®¡:")
            print(f"   ç”Ÿæˆå™¨å¹³å‡æŸå¤±: {avg_gen_loss:.6f}")
            print(f"   åˆ¤åˆ«å™¨å¹³å‡æŸå¤±: {avg_dis_loss:.6f}")

            # å­¦ä¹ ç‡ä¿¡æ¯
            print(f"ğŸ” å­¦ä¹ ç‡:")
            if hasattr(self, 'g_optimizer') and self.g_optimizer is not None:
                g_lr = self.g_optimizer.param_groups[0]['lr']
                print(f"   ç”Ÿæˆå™¨: {g_lr:.6f}")
            if hasattr(self, 'd_optimizer') and self.d_optimizer is not None:
                d_lr = self.d_optimizer.param_groups[0]['lr']
                print(f"   åˆ¤åˆ«å™¨/è¯„è®ºå™¨: {d_lr:.6f}")

            # å…¶ä»–æŒ‡æ ‡
            if metrics:
                print(f"ğŸ“ˆ å…¶ä»–æŒ‡æ ‡:")
                for key, value in metrics.items():
                    print(f"   {key}: {value}")

            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                print(f"ğŸ’¾ GPU å†…å­˜:")
                print(
                    f"   å·²åˆ†é…: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                print(
                    f"   ç¼“å­˜: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
                print(
                    f"   æœ€å¤§åˆ†é…: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB")

            print(f"{separator}\n")

    def train_epoch(self):
        raise NotImplementedError

    def train(self):
        set_random_seed(
            self.args.seed, deterministic=self.args.deterministic, benchmark=self.args.benchmark)
        self.load_checkpoint()

        stop_training = False
        while self.epoch < self.args.epochs and not stop_training:
            # è®­ç»ƒä¸€ä¸ªepoch
            self.train_epoch()

            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler_g.step()
            if self.scheduler_d is not None:
                self.scheduler_d.step()

            # å®šæœŸè¯„ä¼°æ¨¡å‹
            if (self.epoch + 1) % self.eval_interval == 0:
                stop_training = self.evaluate_model()

            # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
            self.save_checkpoint()

            self.epoch += 1

        self.log.close()
        self.log_message(f"Training completed after {self.epoch} epochs.")

    def _apply_spectral_norm(self, model):
        """å¯¹æ¨¡å‹ä¸­çš„å·ç§¯å±‚åº”ç”¨è°±å½’ä¸€åŒ–"""
        for name, module in model.named_modules():
            if isinstance(module, nn.Conv2d):
                spectral_norm(module)

    def _get_optimizers(self, args):
        """è·å–ä¼˜åŒ–å™¨ï¼Œä¸ºç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡"""
        # ç”Ÿæˆå™¨ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
        g_lr = args.lr * 0.5
        # åˆ¤åˆ«å™¨ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ (TTUR)
        d_lr = args.lr * 2.0

        # ä¸ºç”Ÿæˆå™¨ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œè¾ƒå°çš„ beta å€¼
        g_optimizer = torch.optim.Adam(
            self.generator.parameters(),
            lr=g_lr,
            betas=(0.5, 0.999),
            weight_decay=args.weight_decay if hasattr(
                args, 'weight_decay') else 1e-5
        )

        # ä¸ºåˆ¤åˆ«å™¨ä½¿ç”¨ RMSprop ä¼˜åŒ–å™¨ï¼Œæ›´ç¨³å®š
        d_optimizer = None
        if self.discriminator is not None:
            d_optimizer = torch.optim.RMSprop(
                self.discriminator.parameters(),
                lr=d_lr,
                weight_decay=args.weight_decay if hasattr(
                    args, 'weight_decay') else 1e-5
            )
        elif self.critic is not None:
            d_optimizer = torch.optim.RMSprop(
                self.critic.parameters(),
                lr=d_lr,
                weight_decay=args.weight_decay if hasattr(
                    args, 'weight_decay') else 1e-5
            )

        return g_optimizer, d_optimizer

    def add_noise_to_input(self, tensor, noise_factor=None):
        """å‘è¾“å…¥æ·»åŠ å™ªå£°ï¼Œæé«˜ç¨³å®šæ€§"""
        if noise_factor is None:
            noise_factor = self.noise_factor

        if noise_factor > 0:
            noise = torch.randn_like(tensor) * noise_factor
            return tensor + noise
        return tensor

    def _initialize_weights(self, model):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡ï¼Œä½¿ç”¨Kaimingåˆå§‹åŒ–"""
        for m in model.modules():
            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):
                nn.init.kaiming_normal_(
                    m.weight, mode='fan_out', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _check_nan_values(self, loss_value, model_name):
        """æ£€æŸ¥NaNå€¼å¹¶å¤„ç†"""
        if torch.isnan(loss_value).any() or torch.isinf(loss_value).any():
            self.nan_detected = True
            self.nan_count += 1
            self.log_message(f"è­¦å‘Š: æ£€æµ‹åˆ°NaN/Infå€¼åœ¨{model_name}æŸå¤±ä¸­ï¼Œå°è¯•æ¢å¤è®­ç»ƒ...")

            # å¦‚æœè¿ç»­å¤šæ¬¡æ£€æµ‹åˆ°NaNï¼Œé™ä½å­¦ä¹ ç‡
            if self.nan_count >= self.max_nan_count:
                self.log_message(f"è¿ç»­{self.max_nan_count}æ¬¡æ£€æµ‹åˆ°NaNï¼Œé™ä½å­¦ä¹ ç‡...")
                for param_group in self.g_optimizer.param_groups:
                    param_group['lr'] *= 0.5
                if self.d_optimizer is not None:
                    for param_group in self.d_optimizer.param_groups:
                        param_group['lr'] *= 0.5
                self.nan_count = 0

            return True
        else:
            self.nan_detected = False
            self.nan_count = 0
            return False

    def _check_gradients(self, model, model_name):
        """æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaNå€¼"""
        for name, param in model.named_parameters():
            if param.grad is not None:
                if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                    self.log_message(
                        f"è­¦å‘Š: æ£€æµ‹åˆ°NaN/Infæ¢¯åº¦åœ¨{model_name}çš„{name}å‚æ•°ä¸­")
                    param.grad.data.zero_()  # å°†NaNæ¢¯åº¦ç½®é›¶
                    return True
        return False


class StandardGANTrainer(BaseTrainer):
    def __init__(self, args, generator, discriminator):
        super().__init__(args, generator, discriminator=discriminator)
        if discriminator is None:
            raise ValueError("Discriminator model is not initialized.")
        # ä½¿ç”¨ BCEWithLogitsLoss ä»¥å…¼å®¹ autocast
        self.d_loss = nn.BCEWithLogitsLoss().to(self.device)

        # æ·»åŠ  L1 æŸå¤±ç”¨äºåƒç´ çº§ç›‘ç£
        self.l1_loss = nn.L1Loss().to(self.device)

        # æ·»åŠ æ¢¯åº¦ç¼©æ”¾å› å­ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.gradient_scale = 0.1

        # æ·»åŠ å­¦ä¹ ç‡è°ƒæ•´å› å­
        self.lr_decay_factor = 0.5
        self.lr_decay_patience = 5
        self.lr_decay_counter = 0

        # æ·»åŠ æ¢¯åº¦è£å‰ªå€¼
        self.grad_clip_discriminator = 0.5
        self.grad_clip_generator = 1.0

    def compute_generator_loss(self, fake_outputs, fake_images, real_images):
        """è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬"""
        # å¯¹æŠ—æŸå¤± - å¸Œæœ›åˆ¤åˆ«å™¨å°†ç”Ÿæˆçš„å›¾åƒè¯†åˆ«ä¸ºçœŸå®å›¾åƒ
        adv_loss = self.d_loss(fake_outputs, torch.ones_like(fake_outputs))

        # åƒç´ çº§æŸå¤± - ç”Ÿæˆçš„å›¾åƒåº”è¯¥ä¸çœŸå®å›¾åƒç›¸ä¼¼
        pixel_loss = self.l1_loss(fake_images, real_images)

        # æ€»æŸå¤± = å¯¹æŠ—æŸå¤± + åŠ æƒåƒç´ æŸå¤±
        total_loss = adv_loss + pixel_loss * self.pixel_loss_weight

        return total_loss

    def train_epoch(self):
        if self.discriminator is None:
            self.log_message(
                "Discriminator is not initialized. Cannot train GAN.")
            return

        self.discriminator.train()
        self.generator.train()
        source_g = [0.]
        d_g_z2 = 0.
        gen_loss = []
        dis_loss = []

        # ä½¿ç”¨ rich è¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        progress = None
        task_id = None
        if hasattr(self, 'rich_available') and self.rich_available:
            progress = self.create_rich_progress()
            if progress is not None:
                task_id = progress.add_task(
                    f"[cyan]Epoch {self.epoch + 1}/{self.args.epochs}", total=len(self.train_loader))
                progress.start()
        else:
            # ç¾åŒ–è¿›åº¦æ¡
            pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader),
                        bar_format='{l_bar}{bar:10}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                        colour='green', ncols=100)

        # æ¢¯åº¦ç´¯ç§¯ç›¸å…³å˜é‡
        d_loss_accumulator = 0
        g_loss_accumulator = 0
        batch_count = 0

        for i, (low_images, high_images) in enumerate(self.train_loader):
            batch_count += 1
            low_images = low_images.to(self.device)
            high_images = high_images.to(self.device)

            # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦åŒ…å«NaN
            if torch.isnan(low_images).any() or torch.isnan(high_images).any():
                self.log_message("è­¦å‘Š: è¾“å…¥æ•°æ®åŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                continue

            # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ - ä½¿ç”¨æ­£ç¡®çš„autocast
            with autocast(enabled=self.args.autocast):
                # è®­ç»ƒåˆ¤åˆ«å™¨
                for j in range(self.d_updates_per_g):  # ä½¿ç”¨ TTUR
                    if self.d_optimizer is not None:
                        self.d_optimizer.zero_grad(
                            set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶
                    else:
                        continue  # å¦‚æœæ²¡æœ‰åˆ¤åˆ«å™¨ä¼˜åŒ–å™¨ï¼Œè·³è¿‡åˆ¤åˆ«å™¨è®­ç»ƒ

                    # ç”Ÿæˆå‡å›¾åƒ
                    with torch.no_grad():
                        fake = self.generator(low_images)
                    # åˆ¤åˆ«å™¨å¯¹å‡å›¾åƒçš„åˆ¤æ–­
                    fake_inputs = self.discriminator(fake)
                    # åˆ¤åˆ«å™¨å¯¹çœŸå›¾åƒçš„åˆ¤æ–­
                    real_inputs = self.discriminator(high_images)

                    # æ£€æŸ¥åˆ¤åˆ«å™¨è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                    if torch.isnan(fake_inputs).any() or torch.isnan(real_inputs).any():
                        self.log_message("è­¦å‘Š: åˆ¤åˆ«å™¨è¾“å‡ºåŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                        break
                    # åˆ›å»ºæ ‡ç­¾ - ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
                    real_label = torch.ones_like(fake_inputs, requires_grad=False) * (1 - self.label_smoothing) + \
                        torch.rand_like(fake_inputs) * self.label_smoothing
                    fake_label = torch.zeros_like(fake_inputs, requires_grad=False) + \
                        torch.rand_like(fake_inputs) * self.label_smoothing

                    # è®¡ç®—åˆ¤åˆ«å™¨æŸå¤±
                    d_real_output = self.d_loss(real_inputs, real_label)
                    d_x = real_inputs.mean().item()

                    d_fake_output = self.d_loss(fake_inputs, fake_label)
                    d_g_z1 = fake_inputs.mean().item()

                    # æ€»åˆ¤åˆ«å™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬
                    d_output = (d_real_output + d_fake_output) / 2.0

                    # æ·»åŠ æ¢¯åº¦æƒ©ç½š - ä½¿ç”¨æ”¹è¿›çš„æ¢¯åº¦æƒ©ç½šå‡½æ•°
                    if self.lambda_gp > 0:
                        gp = compute_gradient_penalty(
                            self.discriminator, high_images, fake, self.lambda_gp)
                        d_output = d_output + gp

                    # æ£€æŸ¥æŸå¤±å€¼æ˜¯å¦ä¸ºNaN
                    if self._check_nan_values(d_output, "åˆ¤åˆ«å™¨"):
                        break

                    d_loss_accumulator += d_output.item()

                # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ­¥è¿›
                d_output.backward()
                self.d_optimizer.step()

                # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaN
                if self.discriminator is not None:
                    if self._check_gradients(self.discriminator, "åˆ¤åˆ«å™¨"):
                        # å¦‚æœæ£€æµ‹åˆ°NaNæ¢¯åº¦ï¼Œé™ä½å­¦ä¹ ç‡
                        self.lr_decay_counter += 1
                        if self.lr_decay_counter >= self.lr_decay_patience and self.d_optimizer is not None:
                            for param_group in self.d_optimizer.param_groups:
                                param_group['lr'] *= self.lr_decay_factor
                            self.log_message(
                                f"é™ä½åˆ¤åˆ«å™¨å­¦ä¹ ç‡è‡³ {self.d_optimizer.param_groups[0]['lr']}")
                            self.lr_decay_counter = 0
                        break

                # è®­ç»ƒç”Ÿæˆå™¨
                self.g_optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶

                # é‡æ–°ç”Ÿæˆå‡å›¾åƒï¼ˆå› ä¸ºéœ€è¦æ¢¯åº¦ï¼‰
                fake = self.generator(low_images)

                # åˆ¤åˆ«å™¨å¯¹æ–°ç”Ÿæˆçš„å‡å›¾åƒçš„åˆ¤æ–­
                fake_inputs = self.discriminator(fake)

                # è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ä½¿ç”¨ç®€åŒ–çš„æŸå¤±è®¡ç®—å‡½æ•°
                g_output = self.compute_generator_loss(
                    fake_inputs, fake, high_images)

                g_loss_accumulator += g_output.item()

                d_g_z2 = fake_inputs.mean().item()

                # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­
                g_output.backward()
                self.g_optimizer.step()

                # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaN
                if self._check_gradients(self.generator, "ç”Ÿæˆå™¨"):
                    # å¦‚æœæ£€æµ‹åˆ°NaNæ¢¯åº¦ï¼Œé™ä½å­¦ä¹ ç‡
                    self.lr_decay_counter += 1
                    if self.lr_decay_counter >= self.lr_decay_patience and self.g_optimizer is not None:
                        for param_group in self.g_optimizer.param_groups:
                            param_group['lr'] *= self.lr_decay_factor
                        self.log_message(
                            f"é™ä½ç”Ÿæˆå™¨å­¦ä¹ ç‡è‡³ {self.g_optimizer.param_groups[0]['lr']}")
                        self.log_message(
                            f"é™ä½ç”Ÿæˆå™¨å­¦ä¹ ç‡è‡³ {self.g_optimizer.param_groups[0]['lr']}")
                        self.lr_decay_counter = 0
                    continue

                # æ¢¯åº¦ç´¯ç§¯
                if batch_count % self.grad_accum_steps == 0 or i == len(self.train_loader) - 1:
                    # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    torch.nn.utils.clip_grad_norm_(
                        self.generator.parameters(), self.grad_clip_generator)
                    # è®°å½•æŸå¤±
                    gen_loss.append(g_loss_accumulator / self.grad_accum_steps)
                    dis_loss.append(d_loss_accumulator / self.grad_accum_steps)

                    # é‡ç½®ç´¯ç§¯å™¨
                    g_loss_accumulator = 0
                    d_loss_accumulator = 0
                    batch_count = 0

                source_g.append(d_g_z2)

                # æ›´æ–°è¿›åº¦æ¡æè¿°
                if hasattr(self, 'rich_available') and self.rich_available and progress is not None and task_id is not None:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"D: {d_output.item():.4f} | G: {g_output.item():.4f}"
                    metrics = f"D(x): {d_x:.3f} | D(G(z)): {d_g_z2:.3f}"

                    # å®‰å…¨è·å–å­¦ä¹ ç‡
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_d = self.d_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'd_optimizer') and self.d_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_D: {lr_d:.6f}"

                    progress.update(
                        task_id, advance=1, description=f"[cyan]{epoch_info} | {batch_info} | {loss_info} | {metrics} | {lr_info}")
                else:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"D: {d_output.item():.4f} | G: {g_output.item():.4f}"
                    metrics = f"D(x): {d_x:.3f} | D(G(z)): {d_g_z2:.3f}"

                    # æ·»åŠ å­¦ä¹ ç‡ä¿¡æ¯
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_d = self.d_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'd_optimizer') and self.d_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_D: {lr_d:.6f}"

                    if 'pbar' in locals():
                        pbar.set_description(
                            f"ğŸ”„ {epoch_info} | {batch_info} | ğŸ“‰ {loss_info} | ğŸ“Š {metrics} | ğŸ” {lr_info}"
                        )

                # æ¯ä¸ªepochç»“æŸæ—¶ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè€Œä¸æ˜¯æ¯ä¸ªbatch
                if i == len(self.train_loader) - 1:
                    self.save_checkpoint()

        # å…³é—­è¿›åº¦æ¡
        if hasattr(self, 'rich_available') and self.rich_available and progress is not None:
            progress.stop()
        elif 'pbar' in locals():
            pbar.close()

        # è®°å½•è®­ç»ƒæ—¥å¿—
        self.write_log(self.epoch, gen_loss, dis_loss, d_x, d_g_z1, d_g_z2)

        # æ‰“å°è®­ç»ƒæ‘˜è¦
        metrics = {
            "D(x)": d_x,
            "D(G(z))": d_g_z2,
            "PSNR": self.evaluate_model() if self.epoch % 5 == 0 else "æœªè®¡ç®—"
        }
        self.print_epoch_summary(self.epoch, gen_loss, dis_loss, metrics)

        # å¯è§†åŒ–ç»“æœ
        self.visualize_results(self.epoch, gen_loss,
                               dis_loss, high_images, low_images, fake)


class WGAN_GPTrainer(BaseTrainer):
    def __init__(self, args, generator, critic):
        super().__init__(args, generator, critic=critic)
        self.lambda_gp = 10
        if self.critic is None:
            raise ValueError("Critic model is not initialized.")

        # ä½¿ç”¨è‡ªå®šä¹‰ä¼˜åŒ–å™¨
        self.c_optimizer, self.g_optimizer = self._get_wgan_optimizers(args)

        # æ·»åŠ  L1 æŸå¤±ç”¨äºåƒç´ çº§ç›‘ç£
        self.l1_loss = nn.L1Loss().to(self.device)

    def _get_wgan_optimizers(self, args):
        """è·å– WGAN ä¸“ç”¨ä¼˜åŒ–å™¨"""
        # ç”Ÿæˆå™¨ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
        g_lr = args.lr * 0.5
        # è¯„è®ºå™¨ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ (TTUR)
        c_lr = args.lr * 2.0

        # ä¸ºç”Ÿæˆå™¨ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œè¾ƒå°çš„ beta å€¼
        g_optimizer = torch.optim.Adam(
            self.generator.parameters(),
            lr=g_lr,
            betas=(0.5, 0.999),
            weight_decay=args.weight_decay if hasattr(
                args, 'weight_decay') else 1e-5
        )

        # ä¸ºè¯„è®ºå™¨ä½¿ç”¨ RMSprop ä¼˜åŒ–å™¨ï¼Œæ›´ç¨³å®š
        c_optimizer = None
        if self.critic is not None:
            c_optimizer = torch.optim.RMSprop(
                self.critic.parameters(),
                lr=c_lr,
                weight_decay=args.weight_decay if hasattr(
                    args, 'weight_decay') else 1e-5
            )

        return c_optimizer, g_optimizer

    def compute_generator_loss(self, critic_fake, fake_images, real_images):
        """è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬"""
        # å¯¹æŠ—æŸå¤± - å¸Œæœ›è¯„è®ºå™¨ç»™ç”Ÿæˆçš„å›¾åƒé«˜åˆ†
        adv_loss = -torch.mean(critic_fake)

        # åƒç´ çº§æŸå¤± - ç”Ÿæˆçš„å›¾åƒåº”è¯¥ä¸çœŸå®å›¾åƒç›¸ä¼¼
        pixel_loss = self.l1_loss(fake_images, real_images)

        # æ€»æŸå¤± = å¯¹æŠ—æŸå¤± + åŠ æƒåƒç´ æŸå¤± + åŠ æƒæ„ŸçŸ¥æŸå¤±
        total_loss = adv_loss + pixel_loss * self.pixel_loss_weight
        return total_loss

    def train_epoch(self):
        if self.critic is None:
            self.log_message(
                "Critic is not initialized. Cannot train WGAN-GP.")
            return

        self.critic.train()
        self.generator.train()
        source_g = [0.]
        g_z = 0.
        gen_loss = []
        critic_loss = []

        # ä½¿ç”¨ rich è¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        progress = None
        task_id = None
        if hasattr(self, 'rich_available') and self.rich_available:
            progress = self.create_rich_progress()
            if progress is not None:
                task_id = progress.add_task(
                    f"[cyan]Epoch {self.epoch + 1}/{self.args.epochs}", total=len(self.train_loader))
                progress.start()
        else:
            # ç¾åŒ–è¿›åº¦æ¡
            pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader),
                        bar_format='{l_bar}{bar:10}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                        colour='blue', ncols=100)

        # æ¢¯åº¦ç´¯ç§¯ç›¸å…³å˜é‡
        c_loss_accumulator = 0
        g_loss_accumulator = 0
        batch_count = 0

        for i, (low_images, high_images) in enumerate(self.train_loader):
            batch_count += 1
            low_images = low_images.to(self.device)
            high_images = high_images.to(self.device)

            # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦åŒ…å«NaN
            if torch.isnan(low_images).any() or torch.isnan(high_images).any():
                self.log_message("è­¦å‘Š: è¾“å…¥æ•°æ®åŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                continue

            # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ - ä½¿ç”¨æ­£ç¡®çš„autocast
            with autocast(enabled=self.args.autocast):
                # è®­ç»ƒè¯„è®ºå™¨ï¼ˆCriticï¼‰
                for j in range(self.d_updates_per_g):  # ä½¿ç”¨ TTUR
                    if self.c_optimizer is not None:
                        self.c_optimizer.zero_grad(set_to_none=True)
                    else:
                        continue  # å¦‚æœæ²¡æœ‰è¯„è®ºå™¨ä¼˜åŒ–å™¨ï¼Œè·³è¿‡è¯„è®ºå™¨è®­ç»ƒ

                    # ç”Ÿæˆå‡å›¾åƒ
                    with torch.no_grad():
                        fake_images = self.generator(low_images)

                    # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«NaN
                    if torch.isnan(fake_images).any():
                        self.log_message("è­¦å‘Š: ç”Ÿæˆå™¨è¾“å‡ºåŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                        break

                    # æ·»åŠ å™ªå£°åˆ°è¾“å…¥
                    real_with_noise = self.add_noise_to_input(high_images)
                    fake_with_noise = self.add_noise_to_input(
                        fake_images.detach())

                    # è¯„è®ºå™¨å¯¹çœŸå‡å›¾åƒçš„è¯„ä»·
                    critic_real = self.critic(real_with_noise)
                    critic_fake = self.critic(fake_with_noise)

                    # æ£€æŸ¥è¯„è®ºå™¨è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                    if torch.isnan(critic_real).any() or torch.isnan(critic_fake).any():
                        self.log_message("è­¦å‘Š: è¯„è®ºå™¨è¾“å‡ºåŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                        break

                    # è®¡ç®—æ¢¯åº¦æƒ©ç½š
                    gradient_penalty = compute_gradient_penalty(self.critic,
                                                                real_with_noise, fake_with_noise)

                    # æ£€æŸ¥æ¢¯åº¦æƒ©ç½šæ˜¯å¦ä¸ºNaN
                    if torch.isnan(gradient_penalty).any():
                        self.log_message("è­¦å‘Š: æ¢¯åº¦æƒ©ç½šè®¡ç®—ç»“æœä¸ºNaNï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                        break

                    # è®¡ç®—Wassersteinè·ç¦»å’Œæ€»æŸå¤±
                    wasserstein_distance = torch.mean(
                        critic_real) - torch.mean(critic_fake)
                    loss_critic = -wasserstein_distance + self.lambda_gp * gradient_penalty

                    # æ£€æŸ¥æŸå¤±å€¼æ˜¯å¦ä¸ºNaN
                    if self._check_nan_values(loss_critic, "è¯„è®ºå™¨"):
                        break

                    # ç´¯ç§¯æŸå¤±
                    c_loss_accumulator += loss_critic.item()

                    # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ­¥è¿›
                    loss_critic.backward()
                    self.c_optimizer.step()

                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaN
                    if self.critic is not None:
                        if self._check_gradients(self.critic, "è¯„è®ºå™¨"):
                            break

                    # æ¢¯åº¦ç´¯ç§¯
                    if (j == self.d_updates_per_g - 1) and (batch_count % self.grad_accum_steps == 0 or i == len(self.train_loader) - 1):
                        # æ¢¯åº¦è£å‰ª
                        if self.critic is not None and self.c_optimizer is not None:
                            torch.nn.utils.clip_grad_norm_(
                                self.critic.parameters(), 1.0)
                            self.c_optimizer.step()

                # å¦‚æœæ£€æµ‹åˆ°NaNï¼Œè·³è¿‡ç”Ÿæˆå™¨è®­ç»ƒ
                if self.nan_detected:
                    continue

                # è®­ç»ƒç”Ÿæˆå™¨
                self.g_optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶

                # ç”Ÿæˆæ–°çš„å‡å›¾åƒ
                fake_images = self.generator(low_images)

                # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒæ˜¯å¦åŒ…å«NaN
                if torch.isnan(fake_images).any():
                    self.log_message("è­¦å‘Š: ç”Ÿæˆå™¨è¾“å‡ºåŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                    continue

                # è¯„è®ºå™¨å¯¹æ–°ç”Ÿæˆçš„å‡å›¾åƒçš„è¯„ä»·
                critic_fake = self.critic(fake_images)

                # æ£€æŸ¥è¯„è®ºå™¨è¾“å‡ºæ˜¯å¦åŒ…å«NaN
                if torch.isnan(critic_fake).any():
                    self.log_message("è­¦å‘Š: è¯„è®ºå™¨è¾“å‡ºåŒ…å«NaNå€¼ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                    continue

                # è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ä½¿ç”¨ç®€åŒ–çš„æŸå¤±è®¡ç®—å‡½æ•°
                loss_generator = self.compute_generator_loss(
                    critic_fake, fake_images, high_images)

                # æ£€æŸ¥æŸå¤±å€¼æ˜¯å¦ä¸ºNaN
                if self._check_nan_values(loss_generator, "ç”Ÿæˆå™¨"):
                    continue

                g_loss_accumulator += loss_generator.item()

                # è®°å½•è¯„è®ºå™¨å¯¹å‡å›¾åƒçš„å¹³å‡è¯„åˆ†
                g_z = critic_fake.mean().item()

                # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­
                loss_generator.backward()
                self.g_optimizer.step()

                # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaN
                if self._check_gradients(self.generator, "ç”Ÿæˆå™¨"):
                    break

                # æ¢¯åº¦ç´¯ç§¯
                if batch_count % self.grad_accum_steps == 0 or i == len(self.train_loader) - 1:
                    # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    torch.nn.utils.clip_grad_norm_(
                        self.generator.parameters(), 5.0)
                    self.g_optimizer.step()

                    # è®°å½•æŸå¤±
                    gen_loss.append(g_loss_accumulator / self.grad_accum_steps)
                    critic_loss.append(c_loss_accumulator /
                                       self.grad_accum_steps)

                    # é‡ç½®ç´¯ç§¯å™¨
                    g_loss_accumulator = 0
                    c_loss_accumulator = 0
                    batch_count = 0

                source_g.append(g_z)

                # æ›´æ–°è¿›åº¦æ¡æè¿°
                if hasattr(self, 'rich_available') and self.rich_available and progress is not None and task_id is not None:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"C: {loss_critic.item():.4f} | G: {loss_generator.item():.4f}"
                    metrics = f"G(z): {g_z:.3f}"

                    # å®‰å…¨è·å–å­¦ä¹ ç‡
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_c = self.c_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'c_optimizer') and self.c_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_C: {lr_c:.6f}"

                    progress.update(
                        task_id, advance=1, description=f"[cyan]{epoch_info} | {batch_info} | {loss_info} | {metrics} | {lr_info}")
                else:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"C: {loss_critic.item():.4f} | G: {loss_generator.item():.4f}"
                    metrics = f"G(z): {g_z:.3f}"

                    # æ·»åŠ å­¦ä¹ ç‡ä¿¡æ¯
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_c = self.c_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'c_optimizer') and self.c_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_C: {lr_c:.6f}"

                    if 'pbar' in locals():
                        pbar.set_description(
                            f"ğŸ”„ {epoch_info} | {batch_info} | ğŸ“‰ {loss_info} | ğŸ“Š {metrics} | ğŸ” {lr_info}"
                        )

                # æ¯ä¸ªepochç»“æŸæ—¶ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè€Œä¸æ˜¯æ¯ä¸ªbatch
                if i == len(self.train_loader) - 1:
                    self.save_checkpoint()

        # å…³é—­è¿›åº¦æ¡
        if hasattr(self, 'rich_available') and self.rich_available and progress is not None:
            progress.stop()
        elif 'pbar' in locals():
            pbar.close()

        # è®°å½•è®­ç»ƒæ—¥å¿—
        self.write_log(self.epoch, gen_loss, critic_loss, 0, 0, g_z)

        # æ‰“å°è®­ç»ƒæ‘˜è¦
        metrics = {
            "G(z)": g_z,
            "PSNR": self.evaluate_model() if self.epoch % 5 == 0 else "æœªè®¡ç®—"
        }
        self.print_epoch_summary(self.epoch, gen_loss, critic_loss, metrics)

        # å¯è§†åŒ–ç»“æœ
        self.visualize_results(
            self.epoch, gen_loss, critic_loss, high_images, low_images, fake_images)


def train(args):
    generator = Generator()
    discriminator = Discriminator()
    model_structure(generator, (3, 256, 256))
    model_structure(discriminator, (3, 256, 256))
    trainer = StandardGANTrainer(args, generator, discriminator)
    trainer.train()


def train_WGAN(args):
    generator = Generator()
    critic = Discriminator()
    model_structure(generator, (3, 256, 256))
    model_structure(critic, (3, 256, 256))
    trainer = WGAN_GPTrainer(args, generator, critic)
    trainer.train()


class BasePredictor:
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cpu')
        if args.device == 'cuda':
            self.device = torch.device(
                'cuda:0' if torch.cuda.is_available() else 'cpu')
        self.data = args.data
        self.model = args.model
        self.batch_size = args.batch_size
        self.num_workers = args.num_workers
        self.save_path = args.save_path
        self.generator = Generator(1, 1)
        model_structure(
            self.generator, (3, 256, 256))
        checkpoint = torch.load(self.model)
        self.generator.load_state_dict(checkpoint['net'])
        self.generator.to(self.device)
        self.generator.eval()
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

    def predict_images(self):
        raise NotImplementedError

    def predict_video(self):
        raise NotImplementedError


class ImagePredictor(BasePredictor):
    def __init__(self, args):
        super().__init__(args)
        self.test_data = LowLightDataset(
            image_dir=self.data, transform=self.transform, phase="test")
        self.test_loader = DataLoader(self.test_data,
                                      batch_size=self.batch_size,
                                      num_workers=self.num_workers,
                                      drop_last=True)

    def predict_images(self):
        # é˜²æ­¢åŒåè¦†ç›–
        path = save_path(self.save_path, model='predict')
        img_pil = transforms.ToPILImage()
        pbar = tqdm(enumerate(self.test_loader), total=len(self.test_loader), bar_format='{l_bar}{bar:10}| {n_fmt}/{'
                    'total_fmt} {elapsed}')
        torch.no_grad()
        i = 0
        if not os.path.exists(os.path.join(path, 'predictions')):
            os.makedirs(os.path.join(path, 'predictions'))
        for i, (low_images, high_images) in pbar:
            lamb = 255.  # å–ç»å¯¹å€¼æœ€å¤§å€¼ï¼Œé¿å…è´Ÿæ•°è¶…å‡ºç´¢å¼•
            low_images = low_images.to(self.device) / lamb
            high_images = high_images.to(self.device) / lamb

            fake = self.generator(low_images)
            for j in range(self.batch_size):
                fake_img = np.array(
                    img_pil(fake[j]), dtype=np.float32)

                if i > 10 and i % 10 == 0:  # å›¾ç‰‡å¤ªå¤šï¼Œåè½®ä¿å­˜ä¸€æ¬¡
                    img_save_path = os.path.join(
                        path, 'predictions', str(i) + '.jpg')
                    cv2.imwrite(img_save_path, fake_img)
                i = i + 1
            pbar.set_description('Processed %d images' % i)
        pbar.close()

    def predict_video(self):
        raise NotImplementedError  # è¯¥ç±»ä¸æ”¯æŒè§†é¢‘é¢„æµ‹


class VideoPredictor(BasePredictor):
    def __init__(self, args):
        super().__init__(args)
        self.video = args.video
        self.save_video = args.save_video

    def predict_images(self):
        raise NotImplementedError  # è¯¥ç±»ä¸æ”¯æŒå›¾ç‰‡é¢„æµ‹

    def predict_video(self):
        print('running on the device: ', self.device)

        try:
            # ä½¿ç”¨ OpenCV æ‰“å¼€è§†é¢‘ï¼Œé¿å… imageio çš„è¿­ä»£é—®é¢˜
            cap = cv2.VideoCapture(self.data)
            if not cap.isOpened():
                print(f"Error: Could not open video {self.data}")
                return

            # è·å–è§†é¢‘å±æ€§
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            print(
                f"Video properties: {width}x{height}, {fps} FPS, {total_frames} frames")
        except Exception as e:
            print(f"Error opening video: {e}")
            return  # é€€å‡ºå‡½æ•°

        # è®¾ç½®è§†é¢‘å†™å…¥å™¨
        writer = None
        if self.save_video:
            output_path = os.path.join(self.save_path, 'fake.mp4')
            try:
                # ä½¿ç”¨OpenCVçš„VideoWriter
                # ä½¿ç”¨æ•´æ•°å½¢å¼çš„fourccä»£ç ï¼Œé¿å…ä½¿ç”¨VideoWriter_fourcc
                fourcc = int(cv2.VideoWriter.fourcc(
                    'M', 'P', '4', 'V'))  # MP4Vç¼–ç 
                writer = cv2.VideoWriter(output_path, fourcc, fps, (640, 480))

                if not writer.isOpened():
                    print("Error: Could not create video writer")
                    writer = None
            except Exception as e:
                print(f"Error creating video writer: {e}")
                writer = None

        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(os.path.join(self.save_path, 'predictions')):
            os.makedirs(os.path.join(self.save_path, 'predictions'))

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿ no_grad çŠ¶æ€æ­£ç¡®ç®¡ç†
        with torch.no_grad():
            frame_count = 0
            pbar = tqdm(total=total_frames, desc="Processing video frames")

            try:
                while True:
                    # è¯»å–ä¸€å¸§
                    ret, frame = cap.read()
                    if not ret:
                        break  # è§†é¢‘ç»“æŸ

                    # è§†é¢‘å¸§å¤„ç†
                    frame_resized = cv2.resize(frame, (640, 480))
                    frame_pil = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    frame_tensor = torch.tensor(np.array(
                        frame_pil, np.float32) / 255., dtype=torch.float32).to(self.device)
                    frame_tensor = frame_tensor.permute(
                        2, 0, 1).unsqueeze(0)  # [1, 3, 480, 640]

                    # ç”Ÿæˆå¢å¼ºå›¾åƒ
                    fake = self.generator(frame_tensor)
                    fake_np = fake.squeeze(0).permute(
                        1, 2, 0).cpu().detach().numpy()

                    # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼
                    fake_display = (np.clip(fake_np, 0, 1)
                                    * 255).astype(np.uint8)
                    fake_display_bgr = cv2.cvtColor(
                        fake_display, cv2.COLOR_RGB2BGR)

                    # æ˜¾ç¤ºå¸§
                    cv2.imshow('Enhanced', fake_display_bgr)
                    cv2.imshow('Original', frame_resized)

                    # ä¿å­˜è§†é¢‘
                    if self.save_video and writer is not None:
                        writer.write(fake_display_bgr)

                    # æ¯10å¸§ä¿å­˜ä¸€å¼ å›¾ç‰‡
                    if frame_count % 10 == 0:
                        img_save_path = os.path.join(
                            self.save_path, 'predictions', f'frame_{frame_count:04d}.jpg')
                        cv2.imwrite(img_save_path, fake_display_bgr)

                    # æ£€æŸ¥æŒ‰é”®
                    key = cv2.waitKey(1)
                    if key == 27:  # ESCé”®
                        break

                    frame_count += 1
                    pbar.update(1)

            except Exception as e:
                print(f"Error processing video: {e}")

            finally:
                # é‡Šæ”¾èµ„æº
                pbar.close()
                cap.release()
                if writer is not None:
                    writer.release()
                cv2.destroyAllWindows()
                print(f"Processed {frame_count} frames")


def predict(args):
    """é¢„æµ‹å‡½æ•°"""
    if args.mode == 'image':
        predictor = ImagePredictor(args)
        predictor.predict_images()
    elif args.mode == 'video':
        predictor = VideoPredictor(args)
        predictor.predict_video()
    else:
        print("ä¸æ”¯æŒçš„é¢„æµ‹æ¨¡å¼")

    print("é¢„æµ‹å®Œæˆ")


def compute_gradient_penalty(critic, real_samples, fake_samples, lambda_gp=10.0):
    """è®¡ç®—æ¢¯åº¦æƒ©ç½š - æ”¹è¿›ç‰ˆæœ¬ï¼Œå¢åŠ æ•°å€¼ç¨³å®šæ€§"""
    # ç¡®ä¿è¾“å…¥æ²¡æœ‰NaN
    if torch.isnan(real_samples).any() or torch.isnan(fake_samples).any():
        # å¦‚æœè¾“å…¥åŒ…å«NaNï¼Œè¿”å›é›¶æƒ©ç½š
        return torch.tensor(0.0, device=real_samples.device, requires_grad=True)

    batch_size = real_samples.size(0)

    # ç”Ÿæˆéšæœºæ’å€¼ç³»æ•°
    alpha = torch.rand(batch_size, 1, 1, 1, device=real_samples.device)

    # åˆ›å»ºæ’å€¼æ ·æœ¬
    interpolates = real_samples + alpha * (fake_samples - real_samples)
    interpolates.requires_grad_(True)

    # è®¡ç®—è¯„è®ºå™¨å¯¹æ’å€¼æ ·æœ¬çš„è¾“å‡º
    critic_interpolates = critic(interpolates)

    # åˆ›å»ºæ¢¯åº¦è¾“å‡º
    grad_outputs = torch.ones_like(
        critic_interpolates, device=real_samples.device)

    # è®¡ç®—æ¢¯åº¦
    try:
        gradients = torch.autograd.grad(
            outputs=critic_interpolates,
            inputs=interpolates,
            grad_outputs=grad_outputs,
            create_graph=True,
            retain_graph=True,
            only_inputs=True,
        )[0]
    except RuntimeError:
        # å¦‚æœæ¢¯åº¦è®¡ç®—å¤±è´¥ï¼Œè¿”å›é›¶æƒ©ç½š
        print("è­¦å‘Š: æ¢¯åº¦è®¡ç®—å¤±è´¥ï¼Œè¿”å›é›¶æƒ©ç½š")
        return torch.tensor(0.0, device=real_samples.device, requires_grad=True)

    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«NaN
    if torch.isnan(gradients).any():
        print("è­¦å‘Š: æ¢¯åº¦åŒ…å«NaNï¼Œè¿”å›é›¶æƒ©ç½š")
        return torch.tensor(0.0, device=real_samples.device, requires_grad=True)

    # å±•å¹³æ¢¯åº¦å¹¶è®¡ç®—èŒƒæ•°
    gradients = gradients.view(batch_size, -1)

    # æ·»åŠ å°çš„epsilonå€¼ä»¥é˜²æ­¢é™¤é›¶é”™è¯¯
    epsilon = 1e-10
    gradient_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + epsilon)

    # è®¡ç®—æƒ©ç½š - ä½¿ç”¨clampé˜²æ­¢æç«¯å€¼
    gradient_penalty = torch.mean((gradient_norm - 1.0) ** 2)
    gradient_penalty = torch.clamp(gradient_penalty, 0.0, 1000.0)  # é™åˆ¶æƒ©ç½šèŒƒå›´

    return gradient_penalty
