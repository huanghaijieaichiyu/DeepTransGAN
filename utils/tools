import os
import time
import cv2
import numpy as np
import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard.writer import SummaryWriter
from torchvision import transforms
from misic import save_path, set_random_seed
from datasets.data_set import LowLightDataset
from tqdm import tqdm


def setup_training_environment(args):
    """初始化训练环境：路径、设备、随机种子"""
    path = save_path(args.save_path) if not args.resume else args.resume
    os.makedirs(os.path.join(path, 'generator'), exist_ok=True)
    os.makedirs(os.path.join(
        path, 'critic' if args.wgan else 'discriminator'), exist_ok=True)

    device = torch.device('cuda' if args.device ==
                          'cuda' and torch.cuda.is_available() else 'cpu')
    set_random_seed(args.seed, deterministic=args.deterministic,
                    benchmark=args.benchmark)

    return path, device


def create_data_loaders(args):
    """统一创建训练和测试数据加载器"""
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize(args.img_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    train_data = LowLightDataset(args.data, transform=transform, phase="train")
    test_data = LowLightDataset(args.data, transform=transform, phase="test")

    train_loader = DataLoader(train_data, batch_size=args.batch_size,
                              shuffle=True, num_workers=args.num_workers, pin_memory=True)
    test_loader = DataLoader(test_data, batch_size=args.batch_size,
                             shuffle=False, num_workers=args.num_workers)
    return train_loader, test_loader

# models/wgan_gp.py


class WGANGP:
    def __init__(self, generator, critic, args, device):
        self.generator = generator.to(device)
        self.critic = critic.to(device)
        self.args = args
        self.device = device

        # 优化器配置
        self.g_optim = torch.optim.Adam(
            self.generator.parameters(), lr=args.lr, betas=(args.b1, args.b2))
        self.c_optim = torch.optim.Adam(
            self.critic.parameters(), lr=args.lr, betas=(args.b1, args.b2))

        # 自动混合精度
        self.scaler = torch.cuda.amp.GradScaler(enabled=args.amp)

    def train_step(self, real_imgs, low_imgs):
        """WGAN-GP训练步骤"""
        # 训练Critic多次
        for _ in range(self.args.critic_iters):
            with torch.cuda.amp.autocast(enabled=self.args.amp):
                fake = self.generator(low_imgs)
                c_real = self.critic(real_imgs)
                c_fake = self.critic(fake.detach())

                # 计算梯度惩罚
                gp = self.compute_gradient_penalty(real_imgs, fake)
                c_loss = -torch.mean(c_real) + \
                    torch.mean(c_fake) + self.args.lambda_gp * gp

            self.c_optim.zero_grad()
            self.scaler.scale(c_loss).backward()
            self.scaler.step(self.c_optim)

        # 训练Generator一次
        with torch.cuda.amp.autocast(enabled=self.args.amp):
            fake = self.generator(low_imgs)
            c_fake = self.critic(fake)
            g_loss = -torch.mean(c_fake) + nn.MSELoss()(fake, real_imgs)

        self.g_optim.zero_grad()
        self.scaler.scale(g_loss).backward()
        self.scaler.step(self.g_optim)

        self.scaler.update()
        return {'c_loss': c_loss.item(), 'g_loss': g_loss.item()}

    def compute_gradient_penalty(self, real, fake):
        """梯度惩罚计算"""
        alpha = torch.rand(real.size(0), 1, 1, 1, device=self.device)
        interpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)

        d_interpolates = self.critic(interpolates)
        gradients = torch.autograd.grad(
            outputs=d_interpolates, inputs=interpolates,
            grad_outputs=torch.ones_like(d_interpolates),
            create_graph=True, retain_graph=True
        )[0]

        gradients = gradients.view(gradients.size(0), -1)
        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()
